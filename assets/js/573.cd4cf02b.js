(window.webpackJsonp=window.webpackJsonp||[]).push([[573],{3795:function(t,e,a){"use strict";a.r(e);var r=a(7),l=Object(r.a)({},(function(){var t=this,e=t._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"大数据处理-overview"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#大数据处理-overview"}},[t._v("#")]),t._v(" 大数据处理 - Overview")]),t._v(" "),e("p",[t._v("=====================================")]),t._v(" "),e("blockquote",[e("p",[t._v("本文主要介绍大数据处理的一些思路。@pdai")])]),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-overview.html#%E4%BD%95%E8%B0%93%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86",target:"_blank",rel:"noopener noreferrer"}},[t._v("何谓海量数据处理?"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-overview.html#%E5%85%B7%E4%BD%93%E6%80%9D%E8%B7%AF",target:"_blank",rel:"noopener noreferrer"}},[t._v("具体思路"),e("OutboundLink")],1)]),t._v(" "),e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-overview.html#%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0",target:"_blank",rel:"noopener noreferrer"}},[t._v("参考文章"),e("OutboundLink")],1)])]),t._v(" "),e("h1",{attrs:{id:"何谓海量数据处理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#何谓海量数据处理"}},[t._v("#")]),t._v(" 何谓海量数据处理?")]),t._v(" "),e("hr"),t._v(" "),e("p",[t._v("所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。何谓海量，就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。")]),t._v(" "),e("p",[t._v("那解决办法呢?")]),t._v(" "),e("ul",[e("li",[e("code",[t._v("针对时间")]),t._v(": 我们可以采用巧妙的算法搭配合适的数据结构，如Bloom filter/Hash/bit-map/堆/数据库或倒排索引/trie树；")]),t._v(" "),e("li",[e("code",[t._v("针对空间")]),t._v(": 无非就一个办法: 大而化小，分而治之(hash映射);")]),t._v(" "),e("li",[e("code",[t._v("集群|分布式")]),t._v(": 通俗点来讲，单机就是处理装载数据的机器有限(只要考虑cpu，内存，硬盘的数据交互); 而集群适合分布式处理，并行计算(更多考虑节点和节点间的数据交互)。")])]),t._v(" "),e("h1",{attrs:{id:"具体思路"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#具体思路"}},[t._v("#")]),t._v(" 具体思路")]),t._v(" "),e("hr"),t._v(" "),e("ul",[e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-devide-and-hash.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("大数据处理 - 分治/hash/排序"),e("OutboundLink")],1),t._v(" "),e("ul",[e("li",[t._v("就是先映射，而后统计，最后排序:")]),t._v(" "),e("li",[e("code",[t._v("分而治之/hash映射")]),t._v(": 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件，即16字方针: 大而化小，各个击破，缩小规模，逐个解决")]),t._v(" "),e("li",[e("code",[t._v("hash_map统计")]),t._v(": 当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行频率统计。")]),t._v(" "),e("li",[e("code",[t._v("堆/快速排序")]),t._v(": 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP。")])])]),t._v(" "),e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-bloom-filter.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("大数据处理 - Bitmap & Bloom Filter"),e("OutboundLink")],1),t._v(" "),e("ul",[e("li",[t._v("布隆过滤器有着广泛的应用，对于大量数据的“存不存在”的问题在空间上有明显优势，但是在判断存不存在是有一定的错误率(false positive)，也就是说，有可能把不属于这个集合的元素误认为属于这个集合(False Positive)，但不会把属于这个集合的元素误认为不属于这个集合(False Negative)")])])]),t._v(" "),e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-bucket.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("大数据处理 - 双层桶划分"),e("OutboundLink")],1),t._v(" "),e("ul",[e("li",[t._v("其实本质上还是分而治之的思想，重在“分”的技巧上！"),e("code",[t._v("适用范围")]),t._v(": 第k大，中位数，不重复或重复的数字；"),e("code",[t._v("基本原理及要点")]),t._v(": 因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。")])])]),t._v(" "),e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-db-index.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("大数据处理 - Trie树/数据库/倒排索引"),e("OutboundLink")],1),t._v(" "),e("ul",[e("li",[e("code",[t._v("适用范围")]),t._v(": 数据量大，重复多，但是数据种类小可以放入内存；"),e("code",[t._v("基本原理及要点")]),t._v(": 实现方式，节点孩子的表示方式；"),e("code",[t._v("扩展")]),t._v(": 压缩实现")])])]),t._v(" "),e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-outsort.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("大数据处理 - 外排序"),e("OutboundLink")],1),t._v(" "),e("ul",[e("li",[e("code",[t._v("适用范围")]),t._v(": 大数据的排序，去重；"),e("code",[t._v("基本原理及要点")]),t._v(": 外排序的归并方法，置换选择败者树原理，最优归并树")])])]),t._v(" "),e("li",[e("a",{attrs:{href:"https://pdai.tech/md/algorithm/alg-domain-bigdata-map-reduce.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("大数据处理 - Map & Reduce"),e("OutboundLink")],1),t._v(" "),e("ul",[e("li",[t._v("MapReduce是一种计算模型，简单的说就是将大批量的工作(数据)分解(MAP)执行，然后再将结果合并成最终结果(REDUCE)。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序")])])])]),t._v(" "),e("h1",{attrs:{id:"参考文章"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#参考文章"}},[t._v("#")]),t._v(" 参考文章")]),t._v(" "),e("hr"),t._v(" "),e("ul",[e("li",[t._v("https://blog.csdn.net/v_july_v/article/category/1106578")]),t._v(" "),e("li",[t._v("https://blog.csdn.net/v_JULY_v/article/details/6279498")]),t._v(" "),e("li",[t._v("https://blog.csdn.net/v_JULY_v/article/details/7382693")]),t._v(" "),e("li",[t._v("https://blog.csdn.net/meng984611383/article/details/80060096)")])])])}),[],!1,null,null,null);e.default=l.exports}}]);